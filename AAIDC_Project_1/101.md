# Agentic AI Development Course

Full Course GitHub repo: https://github.com/readytensor/rt-agentic-ai-certification 

All resource at KLGiantDev Server 
/home/lukacsk/Development/AgenticAIDevelopmentCourse


# AAIDC Module 1 Project: Foundations of Agentic AI – Your First RAG Assistant

https://app.readytensor.ai/lessons/4n07ViGCey0l


First Week Github Repo: https://github.com/readytensor/rt-agentic-ai-cert-week1 

Full program Github: https://github.com/readytensor/rt-agentic-ai-certification 

## TOC 

### Week 1

- 1.1 What is Agentic AI (AAIDC-Week1-Lesson-1) https://app.readytensor.ai/lessons/g8QivAEShqgw
- 1.2 The Core Components of AI Agents (AAIDC-Week1-Lesson-2) https://app.readytensor.ai/lessons/O8OHY0ehCvdr 
- 1.3 Real-World Applications and Use Cases of Agentic AI (AAIDC-Week1-Lesson-3) https://app.readytensor.ai/lessons/EbfPXrWQMeCh
- 1.4 Agentic AI: Tools of the Trade (AAIDC-Week1-Lesson-4) https://app.readytensor.ai/lessons/hjbeURATH5ul 
- 1.5 Agentic AI: Agents vs. Workflows (AAIDC-Week1-Lesson-5) https://app.readytensor.ai/lessons/Xq3L2HSWLPou 

#### Other suggested articles

- Building effective agents: https://www.anthropic.com/engineering/building-effective-agents 


### Week 2
GitHub repo: https://github.com/readytensor/rt-agentic-ai-cert-week2 

- 2.1 Getting Started with Agentic AI: Free APIs and Local LLM Options (AAIDC-Week2-Setup) https://app.readytensor.ai/lessons/HMONylFlvgvC 
- 2.2 Building Prompts for Agentic AI Systems (AAIDC-Week2-Lesson-1a) https://app.readytensor.ai/lessons/36Hu3DC3TLdu  
- 2.3 Prompt Engineering: Advanced "Reasoning" Techniques (AAIDC-Week2-Lesson-1b) https://app.readytensor.ai/lessons/3jI5t1hwF8wM 
- 2.4 From Text to Data: Hands-On LLM Output Parsing (AAIDC-Week2-Lesson-2) https://app.readytensor.ai/lessons/LHMxs5Dtsv26 
- 2.5 Building Intelligent Pipelines: A Guide to LLM Function Chaining (AAIDC-Week2-Lesson-3) https://app.readytensor.ai/lessons/X51gr9ZwohcW 
- 2.6 Vector Databases: How AI Finds Meaning, Not Just Keywords (AAIDC-Week2-Lesson-4a) https://app.readytensor.ai/lessons/Zdrul0fG17Mg 



#### Most important things
- We need Prompt library in Yaml: https://youtu.be/yeC66lAMbyQ 
- LLMs can handle complex tasks, but when prompted casually, they often skip steps, jump to conclusions, or give surface-level answers. Why? Because under the hood, these models aren't reasoning—they're predicting the next word in a plausible sequence. -> **Chain of Thought, ReAct, and Self-Ask**

![Thinking Flow](./ThinkingFlow.png)

**Chain of Thought** (CoT) follows a linear progression - break the problem down, work through each piece systematically, then synthesize. This mirrors how humans solve math problems or **work through logical puzzles**.

**ReAct** cycles between thinking and doing - consider options, take action, observe results, reflect, then repeat. This matches how humans troubleshoot issues or navigate **complex decisions with multiple variables**. (detective solving a case)

**Self-Ask** starts broad and narrows down - identify what you need to know, ask the right sub-questions, answer each one, then bring it all together. This reflects how humans approach **research or analysis** where the full scope isn't immediately clear. (investigative journalism)

When we say an LLM is using "reasoning" techniques, we need to be honest about what's actually happening under the hood. These models aren't thinking, deliberating, or having insights. They're sophisticated pattern-matching systems performing structured text generation. Let's not forget that modern LLMs are still just doing next-word (token) prediction.

Know when to use each technique: Chain of Thought for logical, step-by-step problems. ReAct for multi-step investigations. Self-Ask for complex, multi-faceted questions.

#### Other suggested articles

- One Model, Five Superpowers: The Versatility of Variational Auto-Encoders : https://app.readytensor.ai/publications/yzN0OCQT7hUS

- CoT: https://arxiv.org/abs/2201.11903 
- ReAct: https://arxiv.org/abs/2210.03629 
- LangChain RAG Chat: https://docs.langchain.com/oss/python/langchain/rag 